#version 1.0
/* ==========================================
## lic.diderot: 2D line integral convolution (LIC) of a flow field

This example performs naive line integral convolution (LIC) in a
2D flow field.  The contrast of the result is modulated by the flow
magnitude (lower contrast at lower velocity), and the coloring is according
to the flow vorticity.

For demonstration purposes, some variables and inputs for this program
are specific to a particular flow field (`../data/sqflow2D.nrrd`),
which we symlink to with `flow.nrrd`.
First we need the noise texture that will be convolved by streamlines
along the flow. This generates `rand.nrrd`:

	ln -s ../data/sqflow2D.nrrd flow.nrrd
	unu slice -i flow.nrrd -a 0 -p 0 | # get a scalar image
	  unu resample -s x4.167 x3.125 | # upsample to ~isotropic image
	  unu 1op nrand -s 42 -o rand.nrrd # randomize with seed 42

The values generated by upsampling are irrelevant; the point of the upsampling
is just to create a new grid that lives in the same world-space location
as the flow data.  Different random values would be generated by different
random seeds.

Then we need a colormap for the vorticity; this generates `cmap.nrrd`.

	echo "0 1 0   1 1 1   1 0 1" |
	  unu reshape -s 3 3 |
	  unu resample -s = 300 -k tent -c node | # now a 3x300 array
	  unu 2op pow - 1.5 | # brighten a bit
	  unu axinfo -a 0 -k rgb | # its an array of colors
	  unu axinfo -a 1 -mm -1 1 | # covers [-1,1]
	  unu dnorm -i - -o cmap.nrrd

With these files in place, we can compile and run `lic.diderot`:

	diderotc --exec lic.diderot
	./lic

The output `rgb.nrrd` needs some post-processing because the results
of LIC on the upstream and down-stream halves of the streamline, which
were computed by separate strands, need to be combined (by averaging).
Looking at the `initially` statement at the very end, the two halves
are indexed last, so they are the fastest axis of the per-strand
output grid. The output array, however, contains RGB values on the
fastest axis, so it is along axis 1 (length 2) that the averaging of
the results of each half are done, followed by quantizing to an 8-bit
image:

	unu project -i rgb.nrrd -a 1 -m mean |
	  unu quantize -b 8 -min 0 -max 1 -o lic.png

The assertion of quantization range [0,1] is based on the smarts used
within the program to anticipate what the contrast of the output will
be, based on the assumption of each streamline sampling
normally-distributed noise. We can use oversampling to anti-alias
(but in this case it comes at 9 times the computational cost):

	OVSMP=3
	./lic -ovsmp $OVSMP
	unu project -i rgb.nrrd -a 1 -m mean |
	  unu resample -s = /$OVSMP /$OVSMP |
	  unu quantize -b 8 -min 0 -max 1 -o lic-$OVSMP.png

========================================== */

input int sizeX ("faster size of LIC output, before oversampling") = 800;
input int sizeY ("slower size of LIC output, before oversampling") = 200;
input real h0 ("step size of streamline integration") = 0.04;
input vec2 xymin ("X,Y at lower corner of bounding box") = [-11.9167,-3.9375];
input vec2 xymax ("X,Y at upper corner of bounding box") = [19.917,3.9375];
/* The defaults for the variables above are based on the image size,
   pixel size, and bounding box of rand.nrrd, as prepared above.
   The inability to learn this information about an image from within a
   Diderot program is a current limitation. Even if it were overcome, it may
   also be challenging to put computed information into the default value
   for an input parameter */
input real vortmax ("vorticity to map to ends of colormap") = 4;
input real velomax ("velocity that produces maximal contrast") = 1;
/* The defaults for the previous two variables depend on the contents
   of the flow field; it is unlikely that these kinds of per-image
   summaries could be part of Diderot itself */
input int ovsmp ("amount of image oversampling (for anti-aliasing)") = 1;
input int stepnum ("# steps in each streamline half") = 30;

/* stdv is the expected standard deviation of the sum of stepnum+0.5
   values from a normal distribution with unit standard deviation,
   which models the convolution sum over each streamline halves (with
   +0.5 because the seed point is counted half, twice). This value is
   used to shift the LIC results from having mean 0 to having mean 0.5 */
real stdv = sqrt(0.5 + stepnum);

field#1(2)[2] V = ctmr ⊛ clamp(image("flow.nrrd"));
field#1(2)[2] nV = V/|V|; // or normalize(V);
field#0(2)[] R = tent ⊛ wrap(image("rand.nrrd"));
field#0(1)[3] cmap = tent ⊛ clamp(image("cmap.nrrd"));

strand LIC(vec2 x0, real sign) {
  /* sign is choosing upstream or downstream integration */
  real h = sign*h0;
  vec2 x = x0;
  /* initializing the convolution sum with half the noise texture at
     the seed point anticipates how the seed point shows up in both
     the upstream and downstream halves of the streamlines, the
     results of which will be added together in post-processing */
  real sum = R(x0)/2;
  int step = 0;
  output vec3 rgb = [0,0,0];

  update {
    x += h*nV(x + 0.5*h*nV(x)); // midpoint method integration
    if (step == stepnum || !inside(x, R)) {
      stabilize;
    }
    sum += R(x);
    step += 1;
  }
  stabilize {
    // include plus and minus 2 standard devs for output gray
    real gray = clamp(0, 1, lerp(0, 1, -2*stdv, sum, 2*stdv));
    // colormap by vorticity
    rgb = cmap(∇×V(x0)/vortmax) * gray;
    // modulate final contrast by sqrt(velocity) at seed point
    rgb = lerp([0.5,0.5,0.5], rgb, min(1, sqrt(|V(x0)|/velomax)));
  }
}
initially [ LIC([lerp(xymin[0], xymax[0], -0.5, xi, ovsmp*sizeX-0.5),
                 lerp(xymin[1], xymax[1], -0.5, yi, ovsmp*sizeY-0.5)],
                 lerp(-1, 1, 0, si, 1))
            | yi in 0..(ovsmp*sizeY-1), // slower image axis
              xi in 0..(ovsmp*sizeX-1), // faster image axis
              si in 0..1 ]; // index into upstream, downstream
