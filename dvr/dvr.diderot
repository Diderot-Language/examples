/* ==========================================
## dvr.diderot: basic direct volume rendering of scalar field

Note that this example is heavily based on the [`mip`](../mip) example;
some of the variables and code are better documented there.

This program needs a dataset `vol.nrrd` to render; [`fs3d-scl`](../fs3d) is one
way to generate this.  Some examples:
* Sphere:  
   `../fs3d/fs3d-scl -which 4 -width 3 | unu save -f nrrd -o vol.nrrd`
* XYZ Coordinate frame:  
   `../fs3d/fs3d-scl -which 12 -width 3.5 -sz0 83 -sz1 84 -sz2 85 | unu save -f nrrd -o vol.nrrd`

The program can be compiled, assuming the directions at
https://github.com/Diderot-Language/examples, with:

	../../vis12/bin/diderotc --exec dvr.diderot

Some example invocations, organized according to dataset examples above
(still in-progress...):
* Sphere:  
   `./dvr ...`
* Coordinate frame:  
   `./dvr ...`
========================================== */

input image(3)[] vol ("volume dataset to render") = image("vol.nrrd");
/* see ../mip/mip.diderot for everything about camera set-up */
input vec3 camEye ("camera look-from point") = [6, 9, 2];
input vec3 camAt ("camera look-at point") = [0, 0, 0];
input vec3 camUp ("camera pseudo-up vector") = [0, 0, 1];
input real camNear ("relative to look-at point, distance to near clipping plane (where rays start from)") = -3;
input real camFar ("relative to look-at point, distance to far clipping plane") = 3;
input real camFOV ("field-of-view angle (in degrees) subtended vertically by view plane") = 15;
input bool camOrtho ("whether to use orthographic, instead of perspective, projection") = false;
input int iresU ("# samples on horizontal axis of image") = 640;
input int iresV ("# samples on vertical axis of image") = 480;
input real rayStep ("inter-sample step along view direction") = 0.1;

input real refStep ("reference (unit) step length, for normalizing opacities") = 0.1;
input real transp0 ("transparency close enough to 0 to terminate ray") = 0.01;
input real isoval ("isovalue at which to render soft isosurface") = 0;
input real thick ("approximate thickness (in world-space) of soft isosurface") = 0.1;
input real maxAlpha ("maximum opacity on rendered surface") = 1.0;
input real phongKa ("Blinn-Phong ambient component") = 0.2;
input real phongKd ("Blinn-Phong diffuse component") = 0.7;
input real phongKs ("Blinn-Phong specular component") = 0.2;
input real phongSp ("Blinn-Phong specularity exponent") = 60;
input vec3 litdir ("direction (non-normalized) towards light source, in (U,V,N) view-space") = [0, 0, -4];
input vec3 mcnear ("material color at near clipping plane (for depth cuing)") = [1,1,1];
input vec3 mcfar ("material color at far clipping plane") = [1,1,1];
input vec4 fog ("fog RGBA inside volume data domain") = [1,1,1,0];
input image(1)[3] cmap ("univariate colormap") = image("cmap.nrrd");
input real zmin ("Z coord mapped to min end of colormap") = 0;
input real zmax ("Z coord mapped to max end of colormap") = 1;

/* Convolve volume data with one of various possible kernels;
   see ../mip/mip.diderot for more info */
//field#0(3)[] V = tent ⊛ vol;
field#1(3)[] V = ctmr ⊛ vol;
//field#2(3)[] V = bspln3 ⊛ vol;
//field#4(3)[] V = c4hexic ⊛ vol;

/* create a field to render from the original volume data field */
field#1(3)[] F = V - isoval;

/* create a field to render from the original volume data field */
field#0(1)[3] CM = tent ⊛ clamp(cmap);

// (boilerplate) computing ray parameters and view-space basis
vec3 camN = normalize(camAt - camEye);  // N: away from eye
vec3 camU = normalize(camN × camUp);    // U: right
vec3 camV = camN × camU;                // V: down (right-handed frame)
real camDist = |camAt - camEye|;
real camVmax = tan(camFOV*π/360)*camDist;
real camUmax = camVmax*iresU/iresV;
real camNearVsp = camNear + camDist; // near clip, view space
real camFarVsp = camFar + camDist;   // far clip, view space
// convert light directions from view-space to world-space
vec3 litwsp = transpose([camU,camV,camN])•normalize(litdir);

/* 2-D opacity function, after Levoy. The 1.4 is a trick to ensure
  that there is a segment of positions receiving maximum opacity. */
function real alpha(real v, real g) = maxAlpha*clamp(0, 1, 1.4 - |v|/(g*thick));

/* normalize opacity aa according to ray step length rsl, so attenuation
   happens in world-space rather than ray sample index space */
function real opacNorm(real aa, real rsl)
   = 1 - pow(1 - aa, rayStep*rsl/refStep);

// how to render ray through (rayU,rayV) on view plane
strand raycast(int ui, int vi /* real rayU, real rayV */) {
   // cell-centered sampling of view plane (intersects look-at)
   real rayU = lerp(-camUmax, camUmax, -0.5, ui, iresU-0.5);
   real rayV = lerp(-camVmax, camVmax, -0.5, vi, iresV-0.5);
   // creation of per-strand ray state based on ../mip/mip.diderot
   real rayN = camNearVsp;
   vec3 UV = rayU*camU + rayV*camV;
   vec3 rayOrig = camEye + (UV if camOrtho else [0,0,0]);
   vec3 rayVec = camN + ([0,0,0] if camOrtho else UV/camDist);
   vec3 eyeDir = -normalize(rayVec);
   // output for this ray
   output vec4 rgba = [0,0,0,0];
   // state for this ray is current color ...
   vec3 rgb = [0,0,0];
   // ... and current tranparency
   real transp = 1;
   /* example of turning on debuging for one pixel;
      can can then have "if (verb) { print(...); }" */
   //bool verb = 369==ui && 242==vi;

   update {
      rayN += rayStep;          // increment ray position
      if (rayN > camFarVsp) {   // ray passed the far clipping plane
         stabilize;
      }
      vec3 pos = rayOrig + rayN*rayVec;  // pos is ray sample position
      if (!inside(pos,F)) {              // If not inside field domain,
         continue;                       // then move onto next iteration
      }
      // compute fog contribution
      real aa = fog[3];
      if (aa > 0) {
         aa = opacNorm(aa, |rayVec|);
         rgb += transp*aa*[fog[0],fog[1],fog[2]];
         transp *= 1 - aa;
      }
      // compute data contribution
      real val = F(pos);
      vec3 grad = -∇F(pos);
      aa = alpha(val, |grad|);
      if (aa == 0) {
         continue;
      }
      aa = opacNorm(aa, |rayVec|);
      // Note: not standard Phong diffuse (no dark hemisphere)
      real dcomp = lerp(0, 1, -1, normalize(grad)•litwsp, 1)^2;
      // Slightly faster as this conditional expression
      real scomp = max(0,normalize(grad)•normalize(eyeDir+litwsp))^phongSp
                   if phongKs != 0 else 0.0;
      // simple depth-cueing
      vec3 dcol = lerp(mcnear, mcfar, camNearVsp, rayN, camFarVsp);
      // lots of things could be basis for material color; this
      // is contrived to show off some univariate mappgin
      vec3 mcol = CM(lerp(0, 1, zmin, pos[2], zmax))
                  if zmin < zmax else [1,1,1];
      rgb += transp*aa*((phongKa + phongKd*dcomp)*modulate(dcol,mcol)
                        + phongKs*scomp*[1,1,1]);
      transp *= 1 - aa;
      if (transp < transp0) { // early ray termination
         transp = 0;
         stabilize;
      }
   }
   stabilize {
      if (transp < 1) {  // un-pre-multiply opacities
         real aa = 1-transp;
         rgba = [rgb[0]/aa, rgb[1]/aa, rgb[2]/aa, aa];
      }
   }
}

initially [ raycast(ui, vi)
            | vi in 0..iresV-1,   // slower
              ui in 0..iresU-1 ]; // faster
